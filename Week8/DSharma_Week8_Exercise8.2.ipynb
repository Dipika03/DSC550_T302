{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51dee3d-ca74-4d1e-a994-0341fee74633",
   "metadata": {},
   "source": [
    "#### Name Dipika Sharma\n",
    "#### DSC 550 T302 Data Mining\n",
    "#### Week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc11622-02d4-4ad1-83ad-ef4daf9880de",
   "metadata": {},
   "source": [
    "## Exercise 8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23414630-7f98-4e76-8eda-4cecda3fb157",
   "metadata": {},
   "source": [
    "### Best Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcbba46-8e12-4afd-8e45-fd63f52d5b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets import the reqired libraries.\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split #used to split data into training/test sets\n",
    "\n",
    "## from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e3b31-1159-44bf-b91b-3814b4f70f97",
   "metadata": {},
   "source": [
    "### 1. Import the dataset and ensure that it loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1bb8c9-5c5c-4e95-9d9c-a34dab75958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets import the dataset Loan_Train.\n",
    "\n",
    "Loan_Train_df = pd.read_csv('Loan_Train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44ac9b0-96d3-4b28-a056-d5402ec70a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets check first five rows of the data frame.\n",
    "\n",
    "Loan_Train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323d40e-b207-4424-aacf-2ea5ea6df26b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Prepare the data for modeling by performing the following steps: \n",
    "#### &emsp;&emsp; Drop the column “Loan_ID.” <br> &emsp;&emsp; Drop any rows with missing data.<br> &emsp;&emsp; Convert the categorical features into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd0f89d-402e-48e4-9260-6dc28b57352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets check how many columns and rows we have in data frame.\n",
    "\n",
    "Loan_Train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a69224-1f89-4144-be97-789593996409",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets drop the column Load_ID from the data frame.\n",
    "\n",
    "Loan_Train_df = Loan_Train_df.drop(['Loan_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44369715-c20e-4ddd-a33a-f357f528d310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets again check how many columns and rows we have in data frame.\n",
    "\n",
    "Loan_Train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad13a4c-e861-4b5a-9d09-fdac70f81f16",
   "metadata": {},
   "source": [
    "#### We can see the number of rows reduce from 13 to 12 after dropping Loan_ID colulmn from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d644cb10-39f8-410e-ae5b-7a87f5154f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using dropna function to drop any rows with missing data in data frame.\n",
    "\n",
    "Loan_Train_df = Loan_Train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0a3779a-5bd8-4aab-8609-6e1c491a1801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets again check how many columns and rows we have in data frame.\n",
    "\n",
    "Loan_Train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e795c1-5471-425f-a32f-490edd06eb3e",
   "metadata": {},
   "source": [
    "#### As we can see after dropping rows with missing values from the data fram the number rows went down from 614 to 480 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042dc67f-d9ff-4702-937f-0f1445458260",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets convert the categorical features of the data frame into the dummy variables.\n",
    "## Lets find out the categorical columns in the dataframe.\n",
    "\n",
    "CateColumns = Loan_Train_df.select_dtypes(\"object\").columns\n",
    "\n",
    "## Storing the categorical columns in a list.\n",
    "\n",
    "CateColumns= list(set(CateColumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde6980b-6210-4355-a141-c1c48409a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets convert the categorical column Loan_status to numerical.\n",
    "## We know if Class status is \"Y\" then code is 1 and if it is \"N\" then the code is 0.\n",
    "\n",
    "Loan_Train_df['Loan_Status_Code'] = Loan_Train_df['Loan_Status'].replace(to_replace=[\"Y\",\"N\"], value=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef01c76e-9835-4bc4-86d8-d563c59afa1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Education',\n",
       " 'Property_Area',\n",
       " 'Dependents',\n",
       " 'Married',\n",
       " 'Loan_Status',\n",
       " 'Self_Employed']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets print out the categorical columns of the dataframe.\n",
    "\n",
    "CateColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62c608f-99de-47b3-a676-c5ee33fc2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the get_dummies function for creating the dummmy variables.\n",
    "\n",
    "Loan_Train_df = pd.get_dummies(Loan_Train_df, columns=CateColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78cb225f-bf17-401e-b85b-b6085fd2a7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Loan_Status_Code</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Education_Graduate</th>\n",
       "      <th>Education_Not Graduate</th>\n",
       "      <th>...</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>Dependents_1</th>\n",
       "      <th>Dependents_2</th>\n",
       "      <th>Dependents_3+</th>\n",
       "      <th>Married_No</th>\n",
       "      <th>Married_Yes</th>\n",
       "      <th>Loan_Status_N</th>\n",
       "      <th>Loan_Status_Y</th>\n",
       "      <th>Self_Employed_No</th>\n",
       "      <th>Self_Employed_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "5             5417             4196.0       267.0             360.0   \n",
       "\n",
       "   Credit_History  Loan_Status_Code  Gender_Female  Gender_Male  \\\n",
       "1             1.0                 0              0            1   \n",
       "2             1.0                 1              0            1   \n",
       "3             1.0                 1              0            1   \n",
       "4             1.0                 1              0            1   \n",
       "5             1.0                 1              0            1   \n",
       "\n",
       "   Education_Graduate  Education_Not Graduate  ...  Dependents_0  \\\n",
       "1                   1                       0  ...             0   \n",
       "2                   1                       0  ...             1   \n",
       "3                   0                       1  ...             1   \n",
       "4                   1                       0  ...             1   \n",
       "5                   1                       0  ...             0   \n",
       "\n",
       "   Dependents_1  Dependents_2  Dependents_3+  Married_No  Married_Yes  \\\n",
       "1             1             0              0           0            1   \n",
       "2             0             0              0           0            1   \n",
       "3             0             0              0           0            1   \n",
       "4             0             0              0           1            0   \n",
       "5             0             1              0           0            1   \n",
       "\n",
       "   Loan_Status_N  Loan_Status_Y  Self_Employed_No  Self_Employed_Yes  \n",
       "1              1              0                 1                  0  \n",
       "2              0              1                 0                  1  \n",
       "3              0              1                 1                  0  \n",
       "4              0              1                 1                  0  \n",
       "5              0              1                 0                  1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets display the top 5 rows of the dataframe.\n",
    "\n",
    "Loan_Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba07adb2-4265-4581-ac59-4d88e214e825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 23)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets check out the number of rows and columns of the new dataframe.\n",
    "\n",
    "Loan_Train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce6ca9-500e-4d93-a06c-2ce42d47b0a2",
   "metadata": {},
   "source": [
    "#### As we can see after adding the dummy variables the number of column increases from 12 to 23."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9dc71b-99dd-40e4-90d2-d698029efbdb",
   "metadata": {},
   "source": [
    "### 3. Split the data into a training and test set, where the “Loan_Status” column is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b39ace91-1ba8-4d26-87d1-67b74b26cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets split the data into a training and test set.\n",
    "\n",
    "X = Loan_Train_df.drop(['Loan_Status_Code','Loan_Status_N','Loan_Status_Y'], axis = 1)\n",
    "\n",
    "Y = Loan_Train_df['Loan_Status_Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e062176a-5801-4456-89bd-3cc68c27933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pareto Principle Split\n",
    "## Using train_test_split function to split the data into 80% training and 20% testing.\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eff3b56-d0fa-49b8-9e9e-9c9e0a09f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets reset the index in the training and test sets.\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "Y_train = Y_train.reset_index(drop = True)\n",
    "Y_test = Y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c78148c-edc5-49d7-a725-9ea1547ffc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X training dataset is: (384, 20)\n",
      "The shape of Y training dataset is: (384,)\n",
      "The shape of X testing dataset is: (96, 20)\n",
      "The shape of Y testing dataset is: (96,)\n"
     ]
    }
   ],
   "source": [
    "## lets check the number of rows and columns of the split data\n",
    "\n",
    "print(\"The shape of X training dataset is: {}\".format(X_train.shape))\n",
    "print(\"The shape of Y training dataset is: {}\".format(Y_train.shape))\n",
    "print(\"The shape of X testing dataset is: {}\".format(X_test.shape))\n",
    "print(\"The shape of Y testing dataset is: {}\".format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac85833-8f38-46d6-bde0-3d41f55ae9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    267\n",
      "0    117\n",
      "Name: Loan_Status_Code, dtype: int64\n",
      "1    65\n",
      "0    31\n",
      "Name: Loan_Status_Code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Lets see how many values of saleprice are in training and test sets\n",
    "\n",
    "print(Y_train.value_counts())\n",
    "print(Y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b24ca083-aed9-4241-8ea6-5275d6b4a3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApplicantIncome            0\n",
      "CoapplicantIncome          0\n",
      "LoanAmount                 0\n",
      "Loan_Amount_Term           0\n",
      "Credit_History             0\n",
      "Gender_Female              0\n",
      "Gender_Male                0\n",
      "Education_Graduate         0\n",
      "Education_Not Graduate     0\n",
      "Property_Area_Rural        0\n",
      "Property_Area_Semiurban    0\n",
      "Property_Area_Urban        0\n",
      "Dependents_0               0\n",
      "Dependents_1               0\n",
      "Dependents_2               0\n",
      "Dependents_3+              0\n",
      "Married_No                 0\n",
      "Married_Yes                0\n",
      "Self_Employed_No           0\n",
      "Self_Employed_Yes          0\n",
      "dtype: int64\n",
      "ApplicantIncome            0\n",
      "CoapplicantIncome          0\n",
      "LoanAmount                 0\n",
      "Loan_Amount_Term           0\n",
      "Credit_History             0\n",
      "Gender_Female              0\n",
      "Gender_Male                0\n",
      "Education_Graduate         0\n",
      "Education_Not Graduate     0\n",
      "Property_Area_Rural        0\n",
      "Property_Area_Semiurban    0\n",
      "Property_Area_Urban        0\n",
      "Dependents_0               0\n",
      "Dependents_1               0\n",
      "Dependents_2               0\n",
      "Dependents_3+              0\n",
      "Married_No                 0\n",
      "Married_Yes                0\n",
      "Self_Employed_No           0\n",
      "Self_Employed_Yes          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Lets look for nulls in both training and test sets.\n",
    "\n",
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eacde56-1031-405f-ae2a-1297a0ae405e",
   "metadata": {},
   "source": [
    "### 4. Create a pipeline with a min-max scaler and a KNN classifier (see section 15.3 in the Machine Learning with Python Cookbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f4eeaf8-1fd3-4236-a561-73302d1052c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets import the required libraries\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44dab222-c01a-4254-a612-08486a33228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets initialize the minmax scaler\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cebcb20d-eeba-498c-956c-d91f636dd730",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets initialize the KNN Classifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "799c8e9d-4903-4828-81d4-c0d9e2ac4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the pipeline with min-max scaler and a KNN classifier\n",
    "\n",
    "pipe_line = Pipeline([(\"scaler\", minmax_scale), (\"knn\", knn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6385173-f24f-4fcc-90da-e2d044cc3d35",
   "metadata": {},
   "source": [
    "### 5. Fit a default KNN classifier to the data with this pipeline. Report the model accuracy on the test set. Note: Fitting a pipeline model works just like fitting a regular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c89f5bbc-1fdb-4d7f-b5a8-afd55f4b182e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;knn&#x27;, KNeighborsClassifier(n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;knn&#x27;, KNeighborsClassifier(n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_jobs=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('knn', KNeighborsClassifier(n_jobs=-1))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets fit a default KNN classifier to the data with the pipeline\n",
    "\n",
    "pipe_line.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "121481bc-f2c1-4045-904f-a8ed0c247349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making prediction on test set\n",
    "\n",
    "Y_pred = pipe_line.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1a47c8b-7af6-418f-92c9-43bafc8e602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculating the model accuracy on the test set.\n",
    "\n",
    "pipe_line.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be374f-5212-4750-961a-52dafbd91658",
   "metadata": {},
   "source": [
    "### 6. Create a search space for your KNN classifier where your “n_neighbors” parameter varies from 1 to 10. (see section 15.3 in the Machine Learning with Python Cookbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfe8c101-3b27-457e-90a0-8bd8ed56b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a search space for KNN classifier.\n",
    "\n",
    "SSpace = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb7687-3cf9-4aae-9f70-fee61b8ecc99",
   "metadata": {},
   "source": [
    "### 7. Fit a grid search with your pipeline, search space, and 5-fold cross-validation to find the best value for the “n_neighbors” parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40274fcb-c404-48fa-a772-444c4dc292be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets instantiate the StandardScaler visualizer\n",
    "\n",
    "StndScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc7ee75a-093e-4443-b582-fb7a84d0d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets fit the visualizer and the model\n",
    "\n",
    "Matrix_X = StndScaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8dd69cc-a910-4248-88ce-dc0b516d96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets do grod search with pipeline.\n",
    "\n",
    "classifier = GridSearchCV(pipe_line, SSpace, cv=5, verbose=0).fit(Matrix_X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea2e7183-2217-4c79-b4f9-a82ad654367b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets find best value for the “n_neighbors” parameter.\n",
    "\n",
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c0353-154b-4961-aae7-88b0e2147b3b",
   "metadata": {},
   "source": [
    "### 8. Find the accuracy of the grid search best model on the test set. Note: It is possible that this will not be an improvement over the default model, but likely it will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f951814e-dc64-4aab-83e2-5b2580122964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters for the KNN tuned hpyerparameters is : {'knn__n_neighbors': 3}\n",
      "The accuracy of the grid search best model on the test set is : 72.29%\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters for the KNN tuned hpyerparameters is : {}\".format(classifier.best_params_))\n",
    "print(\"The accuracy of the grid search best model on the test set is : \", round(classifier.best_score_*100, 2), '%', sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a83101-a71f-460a-9df0-113f3864acd1",
   "metadata": {},
   "source": [
    "### 9. Now, repeat steps 6 and 7 with the same pipeline, but expand your search space to include logistic regression and random forest models with the hyperparameter values in section 12.3 of the Machine Learning with Python Cookbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b09bda76-7cf9-4a69-8cd3-868639239e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeating steps 6 and 7 - pipeline with KNN hyperparameters\n",
    "\n",
    "pipe_line = Pipeline([('StndScaler', StandardScaler()), (\"classifier\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4ed32f0-9b28-4b70-a7a7-fe0dc0dab299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expand search space to include logistic regression and random forest models\n",
    "\n",
    "SSpace=[\n",
    "    {'classifier' : [KNeighborsClassifier()], \n",
    "     'classifier__n_neighbors' : [1,2,3,4,5,6,7,8,9,10]},\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(0, 4, 10),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : [10,100,1000],\n",
    "    'classifier__max_features' : [1, 2, 3]}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54737638-6011-4efc-8784-9693b4fcd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating grid search\n",
    "\n",
    "GSearch = GridSearchCV(pipe_line, SSpace, cv = 5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1083392-c24a-41f1-a778-0cd5e26fec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets fir the grid search.\n",
    "\n",
    "BModel = GSearch.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a502bc1-ef4d-4b9c-a711-179289439399",
   "metadata": {},
   "source": [
    "### 10. What are the best model and hyperparameters found in the grid search? Find the accuracy of this model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5ba176f-e037-45f7-8d34-7febd95dd2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('StndScaler', StandardScaler()),\n",
       "  ('classifier', LogisticRegression(penalty='l1', solver='liblinear'))],\n",
       " 'verbose': False,\n",
       " 'StndScaler': StandardScaler(),\n",
       " 'classifier': LogisticRegression(penalty='l1', solver='liblinear'),\n",
       " 'StndScaler__copy': True,\n",
       " 'StndScaler__with_mean': True,\n",
       " 'StndScaler__with_std': True,\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__dual': False,\n",
       " 'classifier__fit_intercept': True,\n",
       " 'classifier__intercept_scaling': 1,\n",
       " 'classifier__l1_ratio': None,\n",
       " 'classifier__max_iter': 100,\n",
       " 'classifier__multi_class': 'auto',\n",
       " 'classifier__n_jobs': None,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__random_state': None,\n",
       " 'classifier__solver': 'liblinear',\n",
       " 'classifier__tol': 0.0001,\n",
       " 'classifier__verbose': 0,\n",
       " 'classifier__warm_start': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets find out the best model and hyperparameters in grid search.\n",
    "\n",
    "BModel.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22f42cec-a009-461e-a167-cb8c8bec12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets fit grid search.\n",
    "\n",
    "BModel=GSearch.fit(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a38ecc47-c67f-4a8b-b23a-4fa3dc0e1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Best Model is: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of Best Model is:\",BModel.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5dfc0e-2592-47ff-befb-9ed17be643eb",
   "metadata": {},
   "source": [
    "### 11. Summarize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32485f9a-a0ff-45a5-9014-3103afff89c5",
   "metadata": {},
   "source": [
    "#### The Best Model to use with hyperparameters on Loan_Train dataset is Logistic Regression with 76% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464ad8f-1311-4aff-9755-1bd23ace5f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
